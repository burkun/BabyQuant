{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def random_masking_3D(xb, mask_ratio):\n",
    "    # xb: [bs x num_patch x dim]\n",
    "    bs, L, D = xb.shape\n",
    "    x = xb.clone()\n",
    "    \n",
    "    len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "    noise = torch.rand(bs, L, device=xb.device)  # noise in [0, 1], bs x L\n",
    "        \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)                                     # ids_restore: [bs x L]\n",
    "\n",
    "    # keep the first subset\n",
    "    ids_keep = ids_shuffle[:, :len_keep]                                                 # ids_keep: [bs x len_keep]         \n",
    "    x_kept = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))        # x_kept: [bs x len_keep x dim]\n",
    "   \n",
    "    # removed x\n",
    "    x_removed = torch.zeros(bs, L-len_keep, D, device=xb.device)                        # x_removed: [bs x (L-len_keep) x dim]\n",
    "    x_ = torch.cat([x_kept, x_removed], dim=1)                                          # x_: [bs x L x dim]\n",
    "\n",
    "    # combine the kept part and the removed one\n",
    "    x_masked = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1,1,D))    # x_masked: [bs x num_patch x dim]\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([bs, L], device=x.device)                                          # mask: [bs x num_patch]\n",
    "    mask[:, :len_keep] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)                                  # [bs x num_patch]\n",
    "    return x_masked, x_kept, mask, ids_restore\n",
    "\n",
    "def random_masking(xb, mask_ratio):\n",
    "    # xb: [bs x num_patch x n_vars x patch_len]\n",
    "    bs, L, nvars, D = xb.shape\n",
    "    x = xb.clone()\n",
    "    \n",
    "    len_keep = int(L * (1 - mask_ratio))\n",
    "        \n",
    "    noise = torch.rand(bs, L, nvars,device=xb.device)  # noise in [0, 1], bs x L x nvars\n",
    "        \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)                                     # ids_restore: [bs x L x nvars]\n",
    "\n",
    "    # keep the first subset\n",
    "    ids_keep = ids_shuffle[:, :len_keep, :]                                              # ids_keep: [bs x len_keep x nvars]         \n",
    "    x_kept = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, 1, D))     # x_kept: [bs x len_keep x nvars  x patch_len]\n",
    "   \n",
    "    # removed x\n",
    "    x_removed = torch.zeros(bs, L-len_keep, nvars, D, device=xb.device)                 # x_removed: [bs x (L-len_keep) x nvars x patch_len]\n",
    "    x_ = torch.cat([x_kept, x_removed], dim=1)                                          # x_: [bs x L x nvars x patch_len]\n",
    "\n",
    "    # combine the kept part and the removed one\n",
    "    x_masked = torch.gather(x_, dim=1, index=ids_restore.unsqueeze(-1).repeat(1,1,1,D)) # x_masked: [bs x num_patch x nvars x patch_len]\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([bs, L, nvars], device=x.device)                                  # mask: [bs x num_patch x nvars]\n",
    "    mask[:, :len_keep, :] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)                                  # [bs x num_patch x nvars]\n",
    "    return x_masked, x_kept, mask, ids_restore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]])\n"
     ]
    }
   ],
   "source": [
    "xb = torch.rand((1, 10, 1, 10))\n",
    "x_masked, x_kept, mask, ids_restore = random_masking(xb, 0.1)\n",
    "print(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
